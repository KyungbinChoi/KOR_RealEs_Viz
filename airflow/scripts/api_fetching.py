# all code 
import xmltodict
import json
import requests
import pandas as pd
import itertools
import time, os, sys
from datetime import datetime, timedelta
from dateutil.relativedelta import relativedelta
from urllib.parse import unquote

base_date = datetime.strptime(sys.argv[1], "%Y-%m-%d")
update_date = sys.argv[1]

file_path = "/opt/airflow/dataset/results.pkl"
print(f"Checking file path: {file_path}")
if os.path.exists(f"/opt/airflow/dataset/results.pkl"):
    start_date = update_date
else:
    start_date = "2020-01-01"

serviceKey = os.getenv("API_KEY")

API_KEY = unquote(serviceKey)
if not API_KEY:
    raise ValueError("API Key is missing. Please set the API_KEY environment variable.")

def get_month_list(start_date: str, end_date: str):
    start = datetime.strptime(start_date, "%Y-%m-%d")
    end = datetime.strptime(end_date, "%Y-%m-%d")

    # Initialize list to hold the months
    month_list = []

    # Iterate from start to end date by month
    current = start
    while current <= end:
        month_list.append(current.strftime("%Y%m"))
        # Move to the next month
        if current.month == 12:
            current = current.replace(year=current.year + 1, month=1)
        else:
            current = current.replace(month=current.month + 1)

    return month_list

def get_df(lawd_cd, deal_ymd, max_retries=5, sleep_time=1):
    """ íŠ¹ì • ì§€ì—­ê³¼ ë‚ ì§œì˜ ì•„íŒŒíŠ¸ ê±°ëž˜ ë°ì´í„°ë¥¼ ìš”ì²­í•˜ê³  DataFrameìœ¼ë¡œ ë°˜í™˜ """
    base_url = f"http://apis.data.go.kr/1613000/RTMSDataSvcAptTrade/getRTMSDataSvcAptTrade?serviceKey={API_KEY}&LAWD_CD={lawd_cd}&DEAL_YMD={deal_ymd}&pageNo=1&numOfRows=9999"

    for attempt in range(max_retries):
        try:
            res = requests.get(base_url, headers={"User-Agent": "Mozilla/5.0"}, timeout=10)

            # HTTP ìƒíƒœ ì½”ë“œ í™•ì¸
            if res.status_code == 200:
                data = json.loads(json.dumps(xmltodict.parse(res.text)))

                # ë°ì´í„° ì¡´ìž¬ ì—¬ë¶€ í™•ì¸
                if (
                    "response" not in data or
                    "body" not in data["response"] or
                    "items" not in data["response"]["body"] or
                    "item" not in data["response"]["body"]["items"]
                ):
                    print(f"ðŸš¨ No data for LAWD_CD={lawd_cd}, DEAL_YMD={deal_ymd} - Skipping")
                    return pd.DataFrame()  # ë¹ˆ ë°ì´í„°í”„ë ˆìž„ ë°˜í™˜

                item = data["response"]["body"]["items"]["item"]

                # ðŸ”¹ ë°ì´í„°ê°€ ë‹¨ì¼ ê°ì²´(ë”•ì…”ë„ˆë¦¬)ì¼ ê²½ìš° ë¦¬ìŠ¤íŠ¸ë¡œ ë³€í™˜
                if isinstance(item, dict):
                    item = [item]

                df = pd.DataFrame(item)
                return df

            else:
                print(f"âš ï¸ API ìš”ì²­ ì‹¤íŒ¨ (HTTP {res.status_code}), ìž¬ì‹œë„ {attempt + 1}/{max_retries}")

        except (requests.exceptions.RequestException, KeyError, TypeError, ValueError) as e:
            print(f"âš ï¸ ìš”ì²­ ì˜¤ë¥˜ ë°œìƒ: {e}, ìž¬ì‹œë„ {attempt + 1}/{max_retries}")

        time.sleep(sleep_time * (attempt + 1))  # ì§€ìˆ˜ì  ë°±ì˜¤í”„ (ì ì  ê¸´ ëŒ€ê¸° ì‹œê°„)

    print(f"ðŸš¨ ìµœì¢… ìš”ì²­ ì‹¤íŒ¨: LAWD_CD={lawd_cd}, DEAL_YMD={deal_ymd}")
    return pd.DataFrame()  # ìµœì¢…ì ìœ¼ë¡œ ì‹¤íŒ¨í•˜ë©´ ë¹ˆ ë°ì´í„°í”„ë ˆìž„ ë°˜í™˜

def get_multiregion_timeseries_df(lawd_cd_list, deal_ymd_list, sleep_time=1):
    """ ì—¬ëŸ¬ ì§€ì—­ê³¼ ì—¬ëŸ¬ ê°œì›” ë°ì´í„°ë¥¼ ìˆ˜ì§‘í•˜ì—¬ í•˜ë‚˜ì˜ DataFrameìœ¼ë¡œ ë°˜í™˜ """
    df_list = []
    total_requests = len(lawd_cd_list) * len(deal_ymd_list)

    for idx, (cd, month) in enumerate(itertools.product(lawd_cd_list, deal_ymd_list)):
        print(f"[{idx+1}/{total_requests}] Fetching: region={cd}, month={month}")

        smp_df = get_df(cd, month)

        if not smp_df.empty:
            df_list.append(smp_df)

        time.sleep(sleep_time)  # ìš”ì²­ ê°„ ëŒ€ê¸° (ì„œë²„ ë¶€í•˜ ë°©ì§€)

    if df_list:
        return pd.concat(df_list, ignore_index=True)
    else:
        return pd.DataFrame()  # ëª¨ë“  ìš”ì²­ì´ ì‹¤íŒ¨í•˜ë©´ ë¹ˆ DataFrame ë°˜í™˜


if __name__ == "__main__":

    
    print(start_date, update_date)
    deal_ymd_list = get_month_list(start_date, update_date)

    # ì§€ì—­ ì½”ë“œ ëª©ë¡ (ì„œìš¸, ê²½ê¸°)
    region_codes = [
        "11110", "11140", "11170", "11200", "11215", "11230", "11260", "11290", "11305", "11320",
        "11350", "11380", "11410", "11440", "11470", "11500", "11530", "11545", "11560", "11590",
        "11620", "11650", "11680", "11710", "11740",  # ì„œìš¸íŠ¹ë³„ì‹œ
    ]
    region_codes2 = ["41111", "41113", "41115", "41117", "41131", "41133", "41135", "41150", "41171", "41173",
        "41192", "41194", "41196", "41210", "41220", "41250", "41271", "41273", "41281", "41285", "41287", "41290",
        "41310", "41360", "41370", "41390", "41410", "41430", "41450", "41461", "41463", "41465",
        # ê²½ê¸°ë„ (ì¼ë¶€ ì§€ì—­ ì œì™¸)
    ]

    # API ìš”ì²­ ì‹¤í–‰
    smp_timeseries_seoul = get_multiregion_timeseries_df(region_codes, deal_ymd_list)
    smp_timeseries_gyg = get_multiregion_timeseries_df(region_codes2, deal_ymd_list)

    results_df = pd.concat([smp_timeseries_seoul,smp_timeseries_gyg]).reset_index(drop=True)
    results_df.to_pickle(f"/opt/airflow/dataset/results.pkl")
    print('End Data Fetching & Saving raw data set')